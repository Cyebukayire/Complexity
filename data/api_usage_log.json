{
    "gpt-4": {
        "log_requests": [
            {
                "request_id": "chatcmpl-ABq6KQtV0aXHGv8bZZ1JCrv3PabyY",
                "timestamp": "2024-09-26T17:14:08Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 503,
                "output_tokens": 98,
                "total_tokens": 601,
                "cost": 0.02097
            },
            {
                "request_id": "chatcmpl-ABq6QiTTMPSED1Wuu9rcrbz22Osyf",
                "timestamp": "2024-09-26T17:14:14Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 192,
                "output_tokens": 1,
                "total_tokens": 193,
                "cost": 0.00582
            },
            {
                "request_id": "chatcmpl-ABq6QdkwYRPJkoaiJxDE3wI3HUVpE",
                "timestamp": "2024-09-26T17:14:14Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 518,
                "output_tokens": 118,
                "total_tokens": 636,
                "cost": 0.02262
            },
            {
                "request_id": "chatcmpl-ABq6X5wtp0MN3mLdij1DZxevWLv4v",
                "timestamp": "2024-09-26T17:14:21Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 207,
                "output_tokens": 1,
                "total_tokens": 208,
                "cost": 0.0062699999999999995
            },
            {
                "request_id": "chatcmpl-ABq6Y7pWEtjCoQUxKlrShL4EQpCtO",
                "timestamp": "2024-09-26T17:14:22Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 508,
                "output_tokens": 106,
                "total_tokens": 614,
                "cost": 0.0216
            },
            {
                "request_id": "chatcmpl-ABq6e42uWhUefXDvz3WNpa9F9b38e",
                "timestamp": "2024-09-26T17:14:28Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 197,
                "output_tokens": 1,
                "total_tokens": 198,
                "cost": 0.0059700000000000005
            },
            {
                "request_id": "chatcmpl-ABq6eKxZXNz0RSnjbomzHJjwlMMqf",
                "timestamp": "2024-09-26T17:14:28Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 608,
                "output_tokens": 122,
                "total_tokens": 730,
                "cost": 0.02556
            },
            {
                "request_id": "chatcmpl-ABq6nok18akM0pZHLkGs6cWneWrvn",
                "timestamp": "2024-09-26T17:14:37Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 297,
                "output_tokens": 1,
                "total_tokens": 298,
                "cost": 0.008969999999999999
            },
            {
                "request_id": "chatcmpl-ABq6oyLC9GwWP6gNktOI7gmaEqXon",
                "timestamp": "2024-09-26T17:14:38Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 488,
                "output_tokens": 85,
                "total_tokens": 573,
                "cost": 0.01974
            },
            {
                "request_id": "chatcmpl-ABq6tgumik44YyBRRUiGTsv0rhSzs",
                "timestamp": "2024-09-26T17:14:43Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 177,
                "output_tokens": 1,
                "total_tokens": 178,
                "cost": 0.00537
            },
            {
                "request_id": "chatcmpl-ABq6uFRPLVsQsUdJjQYhkXhMfat0r",
                "timestamp": "2024-09-26T17:14:44Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 505,
                "output_tokens": 79,
                "total_tokens": 584,
                "cost": 0.01989
            },
            {
                "request_id": "chatcmpl-ABq6zA7qoZNKFUiGkp8U8OuTlCxln",
                "timestamp": "2024-09-26T17:14:49Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 194,
                "output_tokens": 1,
                "total_tokens": 195,
                "cost": 0.00588
            },
            {
                "request_id": "chatcmpl-ABq6zmx9s18dMI4dE0bhaP9ZdXVEk",
                "timestamp": "2024-09-26T17:14:49Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 761,
                "output_tokens": 128,
                "total_tokens": 889,
                "cost": 0.03051
            },
            {
                "request_id": "chatcmpl-ABq76r2APZQEWpIF26M2vux32Bkvu",
                "timestamp": "2024-09-26T17:14:56Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 450,
                "output_tokens": 1,
                "total_tokens": 451,
                "cost": 0.01356
            },
            {
                "request_id": "chatcmpl-ABq76VD8xk8LZBNmTZdkvkCVYO68P",
                "timestamp": "2024-09-26T17:14:56Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 653,
                "output_tokens": 205,
                "total_tokens": 858,
                "cost": 0.03189
            },
            {
                "request_id": "chatcmpl-ABq7KFPjVHXloKwARBWlIlm3rS2tR",
                "timestamp": "2024-09-26T17:15:10Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 342,
                "output_tokens": 1,
                "total_tokens": 343,
                "cost": 0.01032
            },
            {
                "request_id": "chatcmpl-ABq7L0ZmTYuKWDgHX28HbmjkEobsb",
                "timestamp": "2024-09-26T17:15:11Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 545,
                "output_tokens": 105,
                "total_tokens": 650,
                "cost": 0.02265
            },
            {
                "request_id": "chatcmpl-ABq7SeiW0e9BaUJsQ6guvMvkFdsfM",
                "timestamp": "2024-09-26T17:15:18Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 234,
                "output_tokens": 1,
                "total_tokens": 235,
                "cost": 0.00708
            },
            {
                "request_id": "chatcmpl-ABq7TMXhPAt6ALOovcpxNCTptKJrv",
                "timestamp": "2024-09-26T17:15:19Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 600,
                "output_tokens": 161,
                "total_tokens": 761,
                "cost": 0.027659999999999997
            },
            {
                "request_id": "chatcmpl-ABq7dRCyx5TFQVFOvLE52bja6RKGb",
                "timestamp": "2024-09-26T17:15:29Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 289,
                "output_tokens": 1,
                "total_tokens": 290,
                "cost": 0.008729999999999998
            },
            {
                "request_id": "chatcmpl-ABq7dmRK9aX4WtUDYcscjjzdykM8k",
                "timestamp": "2024-09-26T17:15:29Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 633,
                "output_tokens": 199,
                "total_tokens": 832,
                "cost": 0.03093
            },
            {
                "request_id": "chatcmpl-ABq7obN5Fy8PJxR2uwNZBmH98BejS",
                "timestamp": "2024-09-26T17:15:40Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 322,
                "output_tokens": 1,
                "total_tokens": 323,
                "cost": 0.00972
            },
            {
                "request_id": "chatcmpl-ABq7oYo6AYunLLaeFyXVTO6QHbiNQ",
                "timestamp": "2024-09-26T17:15:40Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 594,
                "output_tokens": 176,
                "total_tokens": 770,
                "cost": 0.028379999999999996
            },
            {
                "request_id": "chatcmpl-ABq80V0DAb3KgLPeqso6aBqxyX5Wp",
                "timestamp": "2024-09-26T17:15:52Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 283,
                "output_tokens": 1,
                "total_tokens": 284,
                "cost": 0.008549999999999999
            },
            {
                "request_id": "chatcmpl-ABq81Bf6MOOyKeuHrqz1FgQQsEr2j",
                "timestamp": "2024-09-26T17:15:53Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 605,
                "output_tokens": 132,
                "total_tokens": 737,
                "cost": 0.02607
            },
            {
                "request_id": "chatcmpl-ABq8A6Uj00PC3KPGkZLuvOxNMT40j",
                "timestamp": "2024-09-26T17:16:02Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 294,
                "output_tokens": 1,
                "total_tokens": 295,
                "cost": 0.008879999999999999
            },
            {
                "request_id": "chatcmpl-ABq8A0Rdazif5U3tQIfkUQCsAb3B7",
                "timestamp": "2024-09-26T17:16:02Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 452,
                "output_tokens": 26,
                "total_tokens": 478,
                "cost": 0.01512
            },
            {
                "request_id": "chatcmpl-ABq8CdYaYwajOKTCp0FF0ObNyGmq7",
                "timestamp": "2024-09-26T17:16:04Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 141,
                "output_tokens": 1,
                "total_tokens": 142,
                "cost": 0.0042899999999999995
            },
            {
                "request_id": "chatcmpl-ABq8D3bFxqjTRJzljrfO4QRWtUP4U",
                "timestamp": "2024-09-26T17:16:05Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 506,
                "output_tokens": 59,
                "total_tokens": 565,
                "cost": 0.01872
            },
            {
                "request_id": "chatcmpl-ABq8HWqWH2bPlj7iwIZTfFiDw9ShA",
                "timestamp": "2024-09-26T17:16:09Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 195,
                "output_tokens": 1,
                "total_tokens": 196,
                "cost": 0.00591
            },
            {
                "request_id": "chatcmpl-ABq8HIjJ0adkgqeaO2IxACmC7Zoeu",
                "timestamp": "2024-09-26T17:16:09Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 562,
                "output_tokens": 111,
                "total_tokens": 673,
                "cost": 0.02352
            },
            {
                "request_id": "chatcmpl-ABq8PIddPSR4mxHOdbnlT0ZVeuMqL",
                "timestamp": "2024-09-26T17:16:17Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 251,
                "output_tokens": 1,
                "total_tokens": 252,
                "cost": 0.0075899999999999995
            },
            {
                "request_id": "chatcmpl-ABq8Qt2IEVMDAMhuI7Pm32xzF1OBk",
                "timestamp": "2024-09-26T17:16:18Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 743,
                "output_tokens": 284,
                "total_tokens": 1027,
                "cost": 0.03932999999999999
            },
            {
                "request_id": "chatcmpl-ABq8kCLvxd2Gm3J3D7gbFA2tYIWS8",
                "timestamp": "2024-09-26T17:16:38Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 432,
                "output_tokens": 1,
                "total_tokens": 433,
                "cost": 0.013019999999999999
            },
            {
                "request_id": "chatcmpl-ABq8kWxFs6DkRRL9lg5Hle6DUBZxB",
                "timestamp": "2024-09-26T17:16:38Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 566,
                "output_tokens": 103,
                "total_tokens": 669,
                "cost": 0.02316
            },
            {
                "request_id": "chatcmpl-ABq8qYg7HzlPekGqQqbJjKdGMuNvA",
                "timestamp": "2024-09-26T17:16:44Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 255,
                "output_tokens": 1,
                "total_tokens": 256,
                "cost": 0.00771
            },
            {
                "request_id": "chatcmpl-ABq8rDUingt92ALOYWfXRBZr87kqt",
                "timestamp": "2024-09-26T17:16:45Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 509,
                "output_tokens": 84,
                "total_tokens": 593,
                "cost": 0.020309999999999998
            },
            {
                "request_id": "chatcmpl-ABq8v45D0jKNwNGXmjdi9rf772fFG",
                "timestamp": "2024-09-26T17:16:49Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 198,
                "output_tokens": 1,
                "total_tokens": 199,
                "cost": 0.006
            },
            {
                "request_id": "chatcmpl-ABq8wtZSVM6YFS3NmvIccnDD7CjpB",
                "timestamp": "2024-09-26T17:16:50Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 537,
                "output_tokens": 88,
                "total_tokens": 625,
                "cost": 0.02139
            },
            {
                "request_id": "chatcmpl-ABq91KE4sc5uTBxxDXGbMO3kH0Nv3",
                "timestamp": "2024-09-26T17:16:55Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 226,
                "output_tokens": 1,
                "total_tokens": 227,
                "cost": 0.00684
            },
            {
                "request_id": "chatcmpl-ABq92eH9kidyLyTvpLaeynuEvvNl8",
                "timestamp": "2024-09-26T17:16:56Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 517,
                "output_tokens": 117,
                "total_tokens": 634,
                "cost": 0.02253
            },
            {
                "request_id": "chatcmpl-ABq99WHJ2AA2saWSLyO1QpGJF16Tm",
                "timestamp": "2024-09-26T17:17:03Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 206,
                "output_tokens": 1,
                "total_tokens": 207,
                "cost": 0.00624
            },
            {
                "request_id": "chatcmpl-ABq9Ax3nZVjkHCH2WyO0ex0P2o93b",
                "timestamp": "2024-09-26T17:17:04Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 617,
                "output_tokens": 115,
                "total_tokens": 732,
                "cost": 0.02541
            },
            {
                "request_id": "chatcmpl-ABq9NvhtMCO425nPOx78SQOO4PM1k",
                "timestamp": "2024-09-26T17:17:17Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 306,
                "output_tokens": 1,
                "total_tokens": 307,
                "cost": 0.009239999999999998
            },
            {
                "request_id": "chatcmpl-ABq9O35igE0mvsgGUKtxarVC9EvnA",
                "timestamp": "2024-09-26T17:17:18Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 731,
                "output_tokens": 255,
                "total_tokens": 986,
                "cost": 0.03723
            },
            {
                "request_id": "chatcmpl-ABq9cxk5O31sPEEGZDFJZ52D00mSo",
                "timestamp": "2024-09-26T17:17:32Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 420,
                "output_tokens": 1,
                "total_tokens": 421,
                "cost": 0.012659999999999998
            },
            {
                "request_id": "chatcmpl-ABq9dxoCvD4VVSKPjMPBsAoTucBnd",
                "timestamp": "2024-09-26T17:17:33Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 615,
                "output_tokens": 146,
                "total_tokens": 761,
                "cost": 0.027209999999999998
            },
            {
                "request_id": "chatcmpl-ABq9l0pIadN5JditxUtBLEJVMJmlH",
                "timestamp": "2024-09-26T17:17:41Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 304,
                "output_tokens": 1,
                "total_tokens": 305,
                "cost": 0.009179999999999999
            },
            {
                "request_id": "chatcmpl-ABq9mlA0qx28cJTCYmu3TSKjlyHIH",
                "timestamp": "2024-09-26T17:17:42Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 571,
                "output_tokens": 159,
                "total_tokens": 730,
                "cost": 0.02667
            },
            {
                "request_id": "chatcmpl-ABq9v6Wytj4LZBw9Pn87Ss2YUNQwk",
                "timestamp": "2024-09-26T17:17:51Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 260,
                "output_tokens": 1,
                "total_tokens": 261,
                "cost": 0.007859999999999999
            },
            {
                "request_id": "chatcmpl-ABq9vlY7fQwMfh2GoFK2fXlpyNFkd",
                "timestamp": "2024-09-26T17:17:51Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 577,
                "output_tokens": 125,
                "total_tokens": 702,
                "cost": 0.02481
            },
            {
                "request_id": "chatcmpl-ABqA3LgWNBJqzSFwOilRTLTJDmOtQ",
                "timestamp": "2024-09-26T17:17:59Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 266,
                "output_tokens": 1,
                "total_tokens": 267,
                "cost": 0.00804
            },
            {
                "request_id": "chatcmpl-ABqA3LMr40HbSTxMK0JENI4LDzJDG",
                "timestamp": "2024-09-26T17:17:59Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 677,
                "output_tokens": 200,
                "total_tokens": 877,
                "cost": 0.032310000000000005
            },
            {
                "request_id": "chatcmpl-ABqAG66DKMzLWFdxhgBSNyx9ERry7",
                "timestamp": "2024-09-26T17:18:12Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 366,
                "output_tokens": 1,
                "total_tokens": 367,
                "cost": 0.01104
            },
            {
                "request_id": "chatcmpl-ABqAHvVUVWfWgKM28DtJAAhnA3q40",
                "timestamp": "2024-09-26T17:18:13Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 749,
                "output_tokens": 185,
                "total_tokens": 934,
                "cost": 0.03357
            },
            {
                "request_id": "chatcmpl-ABqAQ045yKOQQyxmydSzknSnk1boY",
                "timestamp": "2024-09-26T17:18:22Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 438,
                "output_tokens": 1,
                "total_tokens": 439,
                "cost": 0.013199999999999998
            },
            {
                "request_id": "chatcmpl-ABqARR0xt9WmMwdZcNOobmcs2GxcR",
                "timestamp": "2024-09-26T17:18:23Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 640,
                "output_tokens": 160,
                "total_tokens": 800,
                "cost": 0.0288
            },
            {
                "request_id": "chatcmpl-ABqAaVjR52JfhkkJ1HlohxYMOgh8l",
                "timestamp": "2024-09-26T17:18:32Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 329,
                "output_tokens": 1,
                "total_tokens": 330,
                "cost": 0.00993
            },
            {
                "request_id": "chatcmpl-ABqAbXBCN4wwDczmbU3Xilp2QBFCW",
                "timestamp": "2024-09-26T17:18:33Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 576,
                "output_tokens": 154,
                "total_tokens": 730,
                "cost": 0.026519999999999995
            },
            {
                "request_id": "chatcmpl-ABqAl39bsHkPIOPJKpx8arnDnIIMY",
                "timestamp": "2024-09-26T17:18:43Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 265,
                "output_tokens": 1,
                "total_tokens": 266,
                "cost": 0.00801
            },
            {
                "request_id": "chatcmpl-ABqAmXqS3NR62Nzi2MFZnnohs6QzZ",
                "timestamp": "2024-09-26T17:18:44Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 403,
                "output_tokens": 15,
                "total_tokens": 418,
                "cost": 0.01299
            },
            {
                "request_id": "chatcmpl-ABqAnD8NcDirnNPUWJ1Lb1HFzcZID",
                "timestamp": "2024-09-26T17:18:45Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 92,
                "output_tokens": 1,
                "total_tokens": 93,
                "cost": 0.00282
            },
            {
                "request_id": "chatcmpl-ABqAoEdG83QvgDlRDbqtfR36m1hJt",
                "timestamp": "2024-09-26T17:18:46Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 420,
                "output_tokens": 18,
                "total_tokens": 438,
                "cost": 0.013679999999999998
            },
            {
                "request_id": "chatcmpl-ABqAqaSQ97yOWMGKwkKaLLbozcZ5y",
                "timestamp": "2024-09-26T17:18:48Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 109,
                "output_tokens": 1,
                "total_tokens": 110,
                "cost": 0.00333
            },
            {
                "request_id": "chatcmpl-ABqAqw1hUZHlebv2zXGhhDPNFzdKE",
                "timestamp": "2024-09-26T17:18:48Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 670,
                "output_tokens": 184,
                "total_tokens": 854,
                "cost": 0.03114
            },
            {
                "request_id": "chatcmpl-ABqB0ti55DuCW36Y8qXBsomcWXgFv",
                "timestamp": "2024-09-26T17:18:58Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 359,
                "output_tokens": 1,
                "total_tokens": 360,
                "cost": 0.010829999999999998
            },
            {
                "request_id": "chatcmpl-ABqB1QtCjmYEcmdpYiHNBiCfRnwCf",
                "timestamp": "2024-09-26T17:18:59Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 439,
                "output_tokens": 20,
                "total_tokens": 459,
                "cost": 0.014369999999999999
            },
            {
                "request_id": "chatcmpl-ABqB3uyI9ip3PIcivMKMwDAa4zLeu",
                "timestamp": "2024-09-26T17:19:01Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 128,
                "output_tokens": 1,
                "total_tokens": 129,
                "cost": 0.0039000000000000003
            },
            {
                "request_id": "chatcmpl-ABqB3DKUvYH9oZXrGLFc4pWCUphXx",
                "timestamp": "2024-09-26T17:19:01Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 651,
                "output_tokens": 93,
                "total_tokens": 744,
                "cost": 0.02511
            },
            {
                "request_id": "chatcmpl-ABqB8F4LeQpvIkNNaSzeCRlM39LNU",
                "timestamp": "2024-09-26T17:19:06Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 340,
                "output_tokens": 1,
                "total_tokens": 341,
                "cost": 0.01026
            },
            {
                "request_id": "chatcmpl-ABqB9nrXsO4DqOdvpQ5xro61FM1uw",
                "timestamp": "2024-09-26T17:19:07Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 699,
                "output_tokens": 139,
                "total_tokens": 838,
                "cost": 0.02931
            },
            {
                "request_id": "chatcmpl-ABqBGeHIyQLZuhj999hChh5mlniVw",
                "timestamp": "2024-09-26T17:19:14Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 388,
                "output_tokens": 1,
                "total_tokens": 389,
                "cost": 0.011699999999999999
            },
            {
                "request_id": "chatcmpl-ABqBHEwhFMIbHggh0qEruCKOeN7eF",
                "timestamp": "2024-09-26T17:19:15Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 615,
                "output_tokens": 168,
                "total_tokens": 783,
                "cost": 0.02853
            },
            {
                "request_id": "chatcmpl-ABqBRLKhmVCdBY76vZ8VCocGYZk7P",
                "timestamp": "2024-09-26T17:19:25Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 304,
                "output_tokens": 1,
                "total_tokens": 305,
                "cost": 0.009179999999999999
            },
            {
                "request_id": "chatcmpl-ABqBSQvch9NnrImDoASnJVIfv9Cj4",
                "timestamp": "2024-09-26T17:19:26Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 541,
                "output_tokens": 96,
                "total_tokens": 637,
                "cost": 0.021990000000000003
            },
            {
                "request_id": "chatcmpl-ABqBYr9Ef2nf4H7pSFqVWE9wqcOjZ",
                "timestamp": "2024-09-26T17:19:32Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 230,
                "output_tokens": 1,
                "total_tokens": 231,
                "cost": 0.00696
            },
            {
                "request_id": "chatcmpl-ABqBZsBkd5pNmM6WzX6PKMRVDxGRV",
                "timestamp": "2024-09-26T17:19:33Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 673,
                "output_tokens": 184,
                "total_tokens": 857,
                "cost": 0.03123
            },
            {
                "request_id": "chatcmpl-ABqBk3x1klbyRrrRpW5q8g2JiELaf",
                "timestamp": "2024-09-26T17:19:44Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 362,
                "output_tokens": 1,
                "total_tokens": 363,
                "cost": 0.01092
            },
            {
                "request_id": "chatcmpl-ABqBkFRxMvvC5lX52VNBjlAMhgxQc",
                "timestamp": "2024-09-26T17:19:44Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 737,
                "output_tokens": 218,
                "total_tokens": 955,
                "cost": 0.03519
            },
            {
                "request_id": "chatcmpl-ABqBwo6ML2jFKVICUyVaJV0gat2MC",
                "timestamp": "2024-09-26T17:19:56Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 426,
                "output_tokens": 1,
                "total_tokens": 427,
                "cost": 0.012839999999999999
            },
            {
                "request_id": "chatcmpl-ABqBxB2veUiX7pzvgCpABKIYRYPNs",
                "timestamp": "2024-09-26T17:19:57Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 509,
                "output_tokens": 65,
                "total_tokens": 574,
                "cost": 0.01917
            },
            {
                "request_id": "chatcmpl-ABqC1OsNynGalf5Ye7hDLXQLfiAbh",
                "timestamp": "2024-09-26T17:20:01Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 198,
                "output_tokens": 1,
                "total_tokens": 199,
                "cost": 0.006
            },
            {
                "request_id": "chatcmpl-ABqC1XTupVy4s7ymUORUpnRGqq4eX",
                "timestamp": "2024-09-26T17:20:01Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 502,
                "output_tokens": 98,
                "total_tokens": 600,
                "cost": 0.02094
            },
            {
                "request_id": "chatcmpl-ABqC7t4wifbp9J6vDM6Lq7ZAkCfjn",
                "timestamp": "2024-09-26T17:20:07Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 191,
                "output_tokens": 1,
                "total_tokens": 192,
                "cost": 0.00579
            },
            {
                "request_id": "chatcmpl-ABqC85CU6OxNMHUXrVLOJxgx4vGnF",
                "timestamp": "2024-09-26T17:20:08Z",
                "model": "gpt-4-0613",
                "task": "clean text",
                "input_tokens": 705,
                "output_tokens": 203,
                "total_tokens": 908,
                "cost": 0.03333
            },
            {
                "request_id": "chatcmpl-ABqCJNEYXykiTqpSzO6qd7IXRi8uH",
                "timestamp": "2024-09-26T17:20:19Z",
                "model": "gpt-4-0613",
                "task": "count sentences",
                "input_tokens": 394,
                "output_tokens": 1,
                "total_tokens": 395,
                "cost": 0.01188
            }
        ],
        "total_count": {
            "total_number_of_requests": 86,
            "total_input_tokens": 37087,
            "total_output_tokens": 5629,
            "total_tokens": 42716,
            "total_cost": 1.45035
        }
    }
}